{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pratice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eABFmMkavqG_",
        "colab_type": "text"
      },
      "source": [
        "**Import TensorFlow and other important libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WocCHj2IU6Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbffJEiN9uD-",
        "colab_type": "text"
      },
      "source": [
        "load Cifar10 dataset  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H2JV9dG6_rM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "train_images=(train_images.reshape(train_images.shape[0],32,32,3).astype('float32'))\n",
        "train_images=(train_images)/255\n",
        "print(np.shape(train_images))\n",
        "BUFFER_SIZE=50000\n",
        "BATCH_SIZE=256\n",
        "\n",
        "train_dataset=tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIBibwNmqwvE",
        "colab_type": "text"
      },
      "source": [
        "Generator Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB33ttmjH3iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_model():\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256,use_bias=False,input_shape=(100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8,8,256)))\n",
        "  \n",
        "  model.add(layers.Conv2DTranspose(128,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=False))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(3,(5,5),strides=(1,1),padding='same',activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIBbWwDv-76",
        "colab_type": "text"
      },
      "source": [
        "**Sampling for Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY88zS0P4zOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator=generator_model()\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhaUsZh7wE-T",
        "colab_type": "text"
      },
      "source": [
        "**Creating some random noise to display**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CMim2RTA4a9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise=tf.random.normal([1,100])\n",
        "noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8KBsTpswMa7",
        "colab_type": "text"
      },
      "source": [
        "**Display random noise image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7r3LQi2Bp6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_image=generator(noise,training=False)\n",
        "plt.imshow(generate_image[0,:,:,0],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP8uzHT3wUkZ",
        "colab_type": "text"
      },
      "source": [
        "**Discriminator model creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inE1Y1FeAylO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model():\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same',input_shape=[32,32,3]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout((0.4)))\n",
        "\n",
        "  model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='valid'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScqMMo8uwbZf",
        "colab_type": "text"
      },
      "source": [
        "**Discriminator Functionality**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTQtjGqwHGIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator=discriminator_model()\n",
        "decision=discriminator(generate_image)\n",
        "print(decision)\n",
        "discriminator.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JnX1_9kxRIJ",
        "colab_type": "text"
      },
      "source": [
        "**Loss for Generator and Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pXhfgp9HlFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output,fake_output):\n",
        "  real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n",
        "  fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
        "  total_loss=real_loss+fake_loss\n",
        "  return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output),fake_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m74HQMF0xa14",
        "colab_type": "text"
      },
      "source": [
        "**Optimizer for Generator and Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhsJgX9zP6gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbc32VScxio1",
        "colab_type": "text"
      },
      "source": [
        "**Save Checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TlylEYISEnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDt5dFi6xm4H",
        "colab_type": "text"
      },
      "source": [
        "**Experimental Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnetgP0cTK_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch=100\n",
        "noise_dim=100\n",
        "num_generate=10\n",
        "\n",
        "seed=tf.random.normal([num_generate,noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afdy_ujnxswL",
        "colab_type": "text"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRhzK2YEUi5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def training(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as gen_tape, tf.GradientTape(persistent=True) as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb7EE2m9gAIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset,epoch):\n",
        "  for epoch in range(epoch):\n",
        "    start=time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      training(image_batch)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_save_image(generator,epoch+1,seed)\n",
        "\n",
        "    if (epoch+1)%15==0:\n",
        "      checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_save_image(generator,epoch,seed)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2qb7TUPx7pN",
        "colab_type": "text"
      },
      "source": [
        "**Generate and save image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAl7D9dgiEK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_save_image(model,epoch,test_input):\n",
        "  prediction=model(test_input,training=False)\n",
        "\n",
        "  fig=plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(prediction.shape[0]):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(prediction[i,:,:,0]*127.5+127.5,cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig('image at epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0MUMgdAyK7-",
        "colab_type": "text"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnvWoRRTlsFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "train(train_dataset,epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f95k0xjiyXzM",
        "colab_type": "text"
      },
      "source": [
        "**Restore the latest checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTAiGzO4l-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}